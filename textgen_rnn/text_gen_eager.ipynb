{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN text generator using Tensorflow Eager execution\n",
    "#### code originally was using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.7.0\n",
      "Eager execution: True\n",
      "orignal text has 581864 characters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "dataset_filename = 'dataset/holmes.txt'\n",
    "\n",
    "text = open(dataset_filename).read().lower()\n",
    "print('orignal text has {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "    punctuation = ['!', ',', '.', ':', ';', '?']\n",
    "\n",
    "    # get the unique characters in the text\n",
    "    unique_chars = sorted(list(set(text)))\n",
    "    for unique_char in unique_chars:\n",
    "        if unique_char in punctuation:\n",
    "            continue\n",
    "        if unique_char >= 'a' and unique_char <= 'z':\n",
    "            continue\n",
    "        text = text.replace(unique_char, ' ')\n",
    "\n",
    "    return text\n",
    "\n",
    "# remove header and table of contents\n",
    "text = text[1166:]\n",
    "text = cleanup_text(text)\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 573815 total number of characters\n",
      "this corpus has 33 unique characters\n",
      "[' ', '!', ',', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# print(text[:1000])\n",
    "\n",
    "# count the number of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")\n",
    "print (chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character\n",
    "\n",
    "\n",
    "# function that transforms the input text and window-size into a set of input/output pairs \n",
    "def window_transform_text(text, window_size, step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    print('len of text:', len(text))\n",
    "#     num_segments = len(text) // step_size\n",
    "    num_segments = len(text) - window_size\n",
    "    print('num_segments:', num_segments)\n",
    "\n",
    "    for i in range(0, num_segments, step_size):\n",
    "            inputs.append(text[i:i+window_size])\n",
    "\n",
    "    for i in range(0, num_segments, step_size):\n",
    "            offset = window_size+i\n",
    "            outputs.append(text[offset:offset+1])\n",
    "\n",
    "    return inputs,outputs\n",
    "\n",
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text, window_size, step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "#     print(inputs[:10])\n",
    "#     print(outputs[:10])\n",
    "#     return\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.float32)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.float32)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of text: 573815\n",
      "num_segments: 573715\n",
      "X.shape: (114743, 100, 33)\n",
      "y.shape: (114743, 33)\n"
     ]
    }
   ],
   "source": [
    "# produce input/output pairs\n",
    "window_size = 100\n",
    "step_size = 5\n",
    "X,y = encode_io_pairs(text,window_size,step_size)\n",
    "\n",
    "print('X.shape:', X.shape)\n",
    "print('y.shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model using Keras\n",
    "\n",
    "The TensorFlow [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together. See the [Keras documentation](https://keras.io/) for details.\n",
    "\n",
    "The [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, one [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) and one [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 'num_chars' nodes each. The first layer's `input_shape` parameter corresponds to the amount of features from the dataset, and is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars = len(chars) # our vocabulary, i.e. unique characters in text\n",
    "\n",
    "def getModel():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(200, input_shape=(window_size, num_chars)),  # input shape required\n",
    "#         tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(num_chars, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "#### Define the loss and gradient function\n",
    "\n",
    "Both training and evaluation stages need to calculate the model's *[loss](https://developers.google.com/machine-learning/crash-course/glossary#loss)*. This measures how off a model's predictions are from the desired output. We want to minimize, or optimize, this value.\n",
    "\n",
    "Our model will calculate its loss using the [tf.keras.losses.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) function which takes the model's prediction and the desired output. The returned loss value is progressively larger as the prediction gets worse.\n",
    "\n",
    "The `grad` function uses the `loss` function and the [tfe.GradientTape](https://www.tensorflow.org/api_docs/python/tf/contrib/eager/GradientTape) to record operations that compute the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.keras.losses.categorical_crossentropy(y, y_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the optimizer\n",
    "TensorFlow has many [optimization algorithms](https://www.tensorflow.org/api_guides/python/train) available for training. This model uses the [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) that implements the *[stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)* (SGD) algorithm. The `learning_rate` sets the step size to take for each iteration down the hill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 100, 33), (?, 33)), types: (tf.float32, tf.float32)>\n",
      "Epoch 000: Loss: 2.736, Accuracy: 0.000% - in: 895.857 sec.\n",
      "Epoch 001: Loss: 2.267, Accuracy: 0.000% - in: 894.143 sec.\n",
      "Epoch 002: Loss: 2.090, Accuracy: 0.000% - in: 827.263 sec.\n",
      "Epoch 003: Loss: 1.969, Accuracy: 0.000% - in: 814.955 sec.\n",
      "Epoch 004: Loss: 1.876, Accuracy: 0.000% - in: 816.137 sec.\n",
      "Epoch 005: Loss: 1.801, Accuracy: 0.000% - in: 817.035 sec.\n",
      "Epoch 006: Loss: 1.738, Accuracy: 0.000% - in: 817.922 sec.\n",
      "Epoch 007: Loss: 1.682, Accuracy: 0.000% - in: 817.942 sec.\n",
      "Epoch 008: Loss: 1.630, Accuracy: 0.000% - in: 818.598 sec.\n",
      "Epoch 009: Loss: 1.582, Accuracy: 0.000% - in: 819.252 sec.\n",
      "Epoch 010: Loss: 1.536, Accuracy: 0.000% - in: 819.149 sec.\n",
      "Epoch 011: Loss: 1.493, Accuracy: 0.000% - in: 819.292 sec.\n",
      "Epoch 012: Loss: 1.451, Accuracy: 0.000% - in: 820.009 sec.\n",
      "Epoch 013: Loss: 1.410, Accuracy: 0.000% - in: 820.433 sec.\n",
      "Epoch 014: Loss: 1.371, Accuracy: 0.000% - in: 820.718 sec.\n",
      "Epoch 015: Loss: 1.333, Accuracy: 0.000% - in: 821.171 sec.\n",
      "Epoch 016: Loss: 1.295, Accuracy: 0.000% - in: 821.570 sec.\n",
      "Epoch 017: Loss: 1.257, Accuracy: 0.000% - in: 821.655 sec.\n",
      "Epoch 018: Loss: 1.220, Accuracy: 0.000% - in: 821.823 sec.\n",
      "Epoch 019: Loss: 1.183, Accuracy: 0.000% - in: 822.551 sec.\n",
      "Epoch 020: Loss: 1.147, Accuracy: 0.000% - in: 823.323 sec.\n",
      "Epoch 021: Loss: 1.111, Accuracy: 0.000% - in: 822.930 sec.\n",
      "Epoch 022: Loss: 1.079, Accuracy: 0.000% - in: 822.558 sec.\n",
      "Epoch 023: Loss: 1.046, Accuracy: 0.000% - in: 822.783 sec.\n",
      "Epoch 024: Loss: 1.015, Accuracy: 0.000% - in: 822.573 sec.\n",
      "Epoch 025: Loss: 0.991, Accuracy: 0.000% - in: 824.276 sec.\n",
      "Epoch 026: Loss: 0.964, Accuracy: 0.000% - in: 823.469 sec.\n",
      "Epoch 027: Loss: 0.939, Accuracy: 0.000% - in: 823.388 sec.\n",
      "Epoch 028: Loss: 0.917, Accuracy: 0.000% - in: 824.041 sec.\n",
      "Epoch 029: Loss: 0.897, Accuracy: 0.000% - in: 838.317 sec.\n",
      "Epoch 030: Loss: 0.878, Accuracy: 0.000% - in: 826.461 sec.\n",
      "Epoch 031: Loss: 0.862, Accuracy: 0.000% - in: 872.956 sec.\n",
      "Epoch 032: Loss: 0.845, Accuracy: 0.000% - in: 868.360 sec.\n",
      "Epoch 033: Loss: 0.832, Accuracy: 0.000% - in: 882.640 sec.\n",
      "Epoch 034: Loss: 0.818, Accuracy: 0.000% - in: 906.172 sec.\n",
      "Epoch 035: Loss: 0.802, Accuracy: 0.000% - in: 893.869 sec.\n",
      "Epoch 036: Loss: 0.791, Accuracy: 0.000% - in: 884.974 sec.\n",
      "Epoch 037: Loss: 0.777, Accuracy: 0.000% - in: 881.863 sec.\n",
      "Epoch 038: Loss: 0.765, Accuracy: 0.000% - in: 919.762 sec.\n",
      "Epoch 039: Loss: 0.753, Accuracy: 0.000% - in: 905.875 sec.\n",
      "Epoch 040: Loss: 0.742, Accuracy: 0.001% - in: 892.683 sec.\n",
      "Epoch 041: Loss: 0.734, Accuracy: 0.001% - in: 890.519 sec.\n",
      "Epoch 042: Loss: 0.720, Accuracy: 0.001% - in: 851.019 sec.\n",
      "Epoch 043: Loss: 0.713, Accuracy: 0.001% - in: 826.737 sec.\n",
      "Epoch 044: Loss: 0.704, Accuracy: 0.001% - in: 826.016 sec.\n",
      "Epoch 045: Loss: 0.695, Accuracy: 0.002% - in: 826.562 sec.\n",
      "Epoch 046: Loss: 0.687, Accuracy: 0.002% - in: 826.758 sec.\n",
      "Epoch 047: Loss: 0.676, Accuracy: 0.002% - in: 826.948 sec.\n",
      "Epoch 048: Loss: 0.670, Accuracy: 0.003% - in: 826.981 sec.\n",
      "Epoch 049: Loss: 0.662, Accuracy: 0.003% - in: 824.323 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 500\n",
    "\n",
    "# a small subset of our input/output pairs\n",
    "Xsmall = X[:100000,:,:]\n",
    "ysmall = y[:100000,:]\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((Xsmall, ysmall))\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "print(training_dataset)\n",
    "\n",
    "model = getModel()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "    \n",
    "    startTime = time.time()\n",
    "    # training using batches of 'batch_size'\n",
    "    for X, y in tfe.Iterator(training_dataset):\n",
    "        grads = grad(model, X, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables), \n",
    "                                 global_step=tf.train.get_or_create_global_step())\n",
    "        epoch_loss_avg(loss(model, X, y)) # batch loss\n",
    "        epoch_accuracy(model(X), y)\n",
    "        \n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%} - in: {:.3f} sec.\".format(epoch, \n",
    "                                                                    epoch_loss_avg.result(), \n",
    "                                                                    epoch_accuracy.result(),\n",
    "                                                                    (time.time()-startTime)))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAILCAYAAADSeeuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d28ec6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "# axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "# axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "# axes[1].plot(train_accuracy_results)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = 'models/model_large_window_100.hdfs'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    model_filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate text utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses trained model to predict a desired number of future characters\n",
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)), dtype=np.float32)\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        x_test = tf.convert_to_tensor(x_test)\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model(x_test)\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict)                           # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "d finally of the mission which he had accomplished so delicately and successfully for the reigning f\"\n",
      "\n",
      "predicted chars = \n",
      "angs in the onder said he, and then he was dear doust, and little here be the subble to the othere w\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "aders of the daily press, i knew little of my former friend and companion. one night it was on the t\"\n",
      "\n",
      "predicted chars = \n",
      "hat hes and like a room realonge. i shopld to the beld which has been do through the stone plate the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "actice , when my way led me through baker street. as i passed the well remembered door, which must a\"\n",
      "\n",
      "predicted chars = \n",
      " cound spolles stall bark and surpoish of the recimonative a susifelf the hand of the mather pase st\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_inds = [2200, 2400, 2600]\n",
    "\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model, input_chars, num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    print('------------------')\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
